# 순환 뉴럴 네트워크 

6장 컨폴루셔널 네트우워크까지는 일반적인 벡터와 이미지 두 가지 타입의 데이터만을 다루었다. 이미지 타입을 다룰 때는 정제된 속성을 사용하기 위해서 특별한 레이어를 고안했다. 이미지를 픽셀로 변환하더라도 아날로그 TV시절의 테스트 패턴 배경화면처럼 이미지의 내용을 알기가 굉장히 어려워서 특별한 레이어를 사용한다. 

여태까지 우리가 사용했던 데이터는 암묵적으로 어떤 분포에서 동일하게 그려진 iid(독립적이고, 동일하게 분포됨)로 만들어졌지만, 대부분의 데이터는 이렇지 않다. 에를 들면, 이 문단내의 단어들은 순서대로 배치되었지만, 이 문단 내의 단어들을 무작위로 재배치하면 문단을 이해하기에 굉장히 어려워진다. 또, 비디오 안의 이미지 프레임이나, 대화에서의 음성 신호들, 웹사이트를 둘러보는 행동들은 모두 시간순서에 따라 전개된다. 

그리고 순서를 가지는 것 말고 다른 문제도 있다. 입력값들이 전부 연속되는 순서를 가진다는 점이다. 예를 들어서 2, 4, 6, 8, 10, ... 으로 이어지는 작업이 있다고 생각 해보자. 주식시장 예측, 환자의 발열 곡선, 레이싱 카에서 가속해야할 시점 등의 시계열 분석을 할 때 자주 등장하는 작업들이다. 이런 데이터를 처리하기 위한 모델이 필요하게 된다. 

다시 말하면, 컨볼루션 뉴럴 네트쿼크는 효율적으로 공간 정보를 효율적으로 처리할 수 있다면, 순환 네트워크는 순차적인 정보를 처리하기 적합하도록 고안된 네트워크다. 이런 네트워크들은 상태 변수(state varaibels) 를 기존 정보를 저장하는 상태 변수와 현재의 입력값으로 현재의 결괏값을 결정한다. 

순환 뉴럴 네트워크에서 사용되는 많은 예시들은 텍스트 데이터를 사용한다. 그래서 이번 장에서는 언어모델에 대해 집중적으로 다룬다. 언어 모델의 기본 개념에서 논의할 시퀀스 데이터에 대해 정식으로 리뷰를 하고, 이를 바탕으로 순환 뉴럴 네트워크를 디자인할 수 있도록 논의할 것이다. 그리고 순환 뉴럴 네트워크를 훈련하는 동안 마주치는 문제들을 확인할 수 있도록 순환 뉴럴 네트워크의 경사 계산 메소드(gradient calculation method)를 다룬다. 이런 문제들을 풀기위해 LSTM과 GRU와 같은 이미 공개된 순환 뉴럴 네트워크들을 사용할 것이고, 이 장의 후반부에서 더 자세히 설명한다. 

```eval_rst

.. toctree::
   :maxdepth: 2

   sequence(시퀀스)
   lang-model(언어모델)
   rnn(rnn)
   lang-model-dataset(언어모델 데이터셋)
   rnn-scratch(밑바닥부터 시작하는 rnn)
   rnn-gluon(rnn-glon)
   bptt(bptt)
   gru(gru)
   lstm(lstm)
   deep-rnn(deep-rnn)
   bi-rnn(bi-rnn)
```
